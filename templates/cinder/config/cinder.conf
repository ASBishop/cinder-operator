[DEFAULT]
# transport_url = rabbit://openstack:RABBIT_PASS@controller
auth_strategy = keystone
# TODO: Decide if we want the operator to generate the api servers, which is
#       more efficient when creating volumes from image (no keystone requests).
#       For now rely on checking the catalog info
#       glance_api_servers=http://glanceapi.openstack.svc:9292/
glance_catalog_info = image:glance:internalURL
storage_availability_zone = nova
default_availability_zone = nova
# TODO: should we create our own default type
#default_volume_type = openstack-k8s
#enabled_backends = nfs
scheduler_driver = cinder.scheduler.filter_scheduler.FilterScheduler

# Reduce to 30 seconds, from default's 60, the wait to receive 1 service
# capabilities report from a cinder volume service.  We keep it under the value
# of service_down_time (default 60) to ensure that the probes don't restart the
# scheduler.
scheduler_driver_init_wait_time = 30

# osapi_volume_listen=controller-0.internalapi.redhat.local
osapi_volume_workers = 4
control_exchange = openstack
api_paste_config = /etc/cinder/api-paste.ini
# cinder-backup
# set in custom config CM
#backup_driver = cinder.backup.drivers.nfs.NFSBackupDriver
#backup_share = 192.168.111.1:/home/nfs/cinder-backup

# For containers we want to log to stdout instead of the default stderr, as
# that would make cinder-api logs be treated as errors by httpd
log_file = /dev/stdout

[database]
# connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder
max_retries = -1
db_max_retries = -1

# TODO:
#[oslo_messaging_notifications]
#transport_url = rabbit://stackrabbit:secret@192.168.122.19:5672/
#driver = messagingv2

[oslo_messaging_rabbit]
heartbeat_timeout_threshold=60

[oslo_middleware]
enable_proxy_headers_parsing=True

[keystone_authtoken]
www_authenticate_uri={{ .KeystonePublicURL }}
auth_url={{ .KeystonePublicURL }}
# TODO (mschuppert): Add memcached
#memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = {{ .ServiceUser }}
#service_token_roles_required = true

[nova]
interface = admin
auth_type = password
auth_url = {{ .KeystonePublicURL }}
#TODO: username
username = nova
user_domain_name = Default
project_name = service
project_domain_name = Default

#TODO
#[service_user]
#send_service_user_token = True
#TODO
#auth_url = http://keystone.openstack.svc:5000/
#project_name = service
#project_domain_name = Default
#username = cinder
#user_domain_name = Default
#auth_type = password

[oslo_concurrency]
lock_path = /var/locks/openstack/cinder

[os_brick]
lock_path = /var/locks/openstack/os-brick

# default backend for dev
# Set in volume custom config CM
#[nfs]
#backend_host=hostgroup
#volume_backend_name=nfs
#volume_driver=cinder.volume.drivers.nfs.NfsDriver
#nfs_shares_config=/etc/cinder/nfs_shares

[ceph]
volume_backend_name=ceph
volume_driver=cinder.volume.drivers.rbd.RBDDriver
rbd_ceph_conf=/etc/ceph/ceph.conf
rbd_user={{ .User }}
rbd_pool={{ .Pool }}
rbd_flatten_volume_from_snapshot=False
rbd_secret_uuid={{ .ClusterFSID }}
